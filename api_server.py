# api_server.py
# æ–°ä¸€ä»£ LMArena - å¯¹æˆ˜ä¸“ç”¨æœåŠ¡å™¨

import asyncio
import json
import logging
import os
import sys
import subprocess
import time
import uuid
import re
import random
from datetime import datetime
from contextlib import asynccontextmanager

import uvicorn
import requests
import httpx  # ç”¨äºå‘å¤–éƒ¨ä»£ç†å‘é€HTTPè¯·æ±‚
from packaging.version import parse as parse_version
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse, Response

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
# image_generation å·²è¢«ç§»é™¤ï¼Œå› ä¸ºå®ƒä¾èµ–äºæ—§çš„ä»£ç†é€»è¾‘
from modules import battle_db
from modules import battle_mode_handler
from modules import elo_manager

# --- åŸºç¡€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- å…¨å±€çŠ¶æ€ä¸é…ç½® ---
CONFIG = {} # å­˜å‚¨ä» config.jsonc åŠ è½½çš„é…ç½®
last_activity_time = None # è®°å½•æœ€åä¸€æ¬¡æ´»åŠ¨çš„æ—¶é—´
main_event_loop = None # ä¸»äº‹ä»¶å¾ªç¯

# æ–°å¢: å¤–éƒ¨ä»£ç†æœåŠ¡åœ°å€
# å¯¹æˆ˜æœåŠ¡å™¨å°†é€šè¿‡æ­¤åœ°å€è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤
PROXY_URL = "http://127.0.0.1:5102" 

# --- æ¨¡å‹æ±  ---
MODEL_POOL = [] # ç”¨äºä» models.json å­˜å‚¨å¯ç”¨çš„æ¨¡å‹ID
DEFAULT_MODEL_ID = "default-model" # é»˜è®¤æ¨¡å‹

def load_model_pool():
    """ä» models.json åŠ è½½å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ã€‚"""
    global MODEL_POOL
    try:
        with open('models.json', 'r', encoding='utf-8') as f:
            models = json.load(f)
            if isinstance(models, list):
                MODEL_POOL = models
                logger.info(f"æˆåŠŸä» 'models.json' åŠ è½½äº† {len(MODEL_POOL)} ä¸ªæ¨¡å‹ã€‚")
            else:
                logger.error("'models.json' çš„å†…å®¹ä¸æ˜¯ä¸€ä¸ªJSONåˆ—è¡¨ã€‚")
                MODEL_POOL = []
    except FileNotFoundError:
        logger.warning("'models.json' æ–‡ä»¶æœªæ‰¾åˆ°ã€‚å°†ä½¿ç”¨ç©ºæ¨¡å‹æ± ã€‚")
        MODEL_POOL = []
    except json.JSONDecodeError as e:
        logger.error(f"åŠ è½½æˆ–è§£æ 'models.json' å¤±è´¥: {e}ã€‚")
        MODEL_POOL = []

def load_config():
    """ä» config.jsonc åŠ è½½é…ç½®ï¼Œå¹¶å¤„ç† JSONC æ³¨é‡Šã€‚"""
    global CONFIG
    try:
        with open('config.jsonc', 'r', encoding='utf-8') as f:
            content = f.read()
            json_content = re.sub(r'//.*', '', content)
            json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
            CONFIG = json.loads(json_content)
        logger.info("æˆåŠŸä» 'config.jsonc' åŠ è½½é…ç½®ã€‚")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"åŠ è½½æˆ–è§£æ 'config.jsonc' å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
        CONFIG = {}

# --- æ›´æ–°æ£€æŸ¥ (ä¿ç•™) ---
GITHUB_REPO = "Lianues/LMArenaBridge"

def download_and_extract_update(version):
    """ä¸‹è½½å¹¶è§£å‹æœ€æ–°ç‰ˆæœ¬åˆ°ä¸´æ—¶æ–‡ä»¶å¤¹ã€‚"""
    update_dir = "update_temp"
    if not os.path.exists(update_dir):
        os.makedirs(update_dir)
    try:
        zip_url = f"https://github.com/{GITHUB_REPO}/archive/refs/heads/main.zip"
        logger.info(f"æ­£åœ¨ä» {zip_url} ä¸‹è½½æ–°ç‰ˆæœ¬...")
        response = requests.get(zip_url, timeout=60)
        response.raise_for_status()
        import zipfile
        import io
        with zipfile.ZipFile(io.BytesIO(response.content)) as z:
            z.extractall(update_dir)
        logger.info(f"æ–°ç‰ˆæœ¬å·²æˆåŠŸä¸‹è½½å¹¶è§£å‹åˆ° '{update_dir}' æ–‡ä»¶å¤¹ã€‚")
        return True
    except Exception as e:
        logger.error(f"ä¸‹è½½æˆ–è§£å‹æ›´æ–°å¤±è´¥: {e}")
        return False

def check_for_updates():
    """ä» GitHub æ£€æŸ¥æ–°ç‰ˆæœ¬ã€‚"""
    if not CONFIG.get("enable_auto_update", True):
        logger.info("è‡ªåŠ¨æ›´æ–°å·²ç¦ç”¨ï¼Œè·³è¿‡æ£€æŸ¥ã€‚")
        return

    current_version = CONFIG.get("version", "0.0.0")
    logger.info(f"å½“å‰ç‰ˆæœ¬: {current_version}ã€‚æ­£åœ¨ä» GitHub æ£€æŸ¥æ›´æ–°...")

    try:
        config_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/config.jsonc"
        response = requests.get(config_url, timeout=10)
        response.raise_for_status()
        jsonc_content = response.text
        json_content = re.sub(r'//.*', '', jsonc_content)
        json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
        remote_config = json.loads(json_content)
        remote_version_str = remote_config.get("version")
        if not remote_version_str:
            logger.warning("è¿œç¨‹é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç‰ˆæœ¬å·ï¼Œè·³è¿‡æ›´æ–°æ£€æŸ¥ã€‚")
            return

        if parse_version(remote_version_str) > parse_version(current_version):
            logger.info("="*60)
            logger.info(f"ğŸ‰ å‘ç°æ–°ç‰ˆæœ¬! ğŸ‰ (æœ€æ–°: {remote_version_str})")
            if download_and_extract_update(remote_version_str):
                logger.info("å‡†å¤‡åº”ç”¨æ›´æ–°ã€‚æœåŠ¡å™¨å°†åœ¨5ç§’åå…³é—­å¹¶å¯åŠ¨æ›´æ–°è„šæœ¬ã€‚")
                time.sleep(5)
                update_script_path = os.path.join("modules", "update_script.py")
                subprocess.Popen([sys.executable, update_script_path])
                os._exit(0)
            else:
                logger.error(f"è‡ªåŠ¨æ›´æ–°å¤±è´¥ã€‚è¯·è®¿é—® https://github.com/{GITHUB_REPO}/releases/latest æ‰‹åŠ¨ä¸‹è½½ã€‚")
            logger.info("="*60)
        else:
            logger.info("æ‚¨çš„ç¨‹åºå·²æ˜¯æœ€æ–°ç‰ˆæœ¬ã€‚")
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ›´æ–°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# --- FastAPI ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶è¿è¡Œçš„ç”Ÿå‘½å‘¨æœŸå‡½æ•°ã€‚"""
    global last_activity_time, main_event_loop
    main_event_loop = asyncio.get_running_loop()
    load_config()
    check_for_updates()
    load_model_pool()
    
    # åˆå§‹åŒ–æ•°æ®åº“
    battle_db.init_db()
    elo_manager.init_db()
    
    logger.info("="*60)
    logger.info("ğŸš€ LMArena å¯¹æˆ˜æœåŠ¡å™¨å·²æˆåŠŸå¯åŠ¨ ğŸš€")
    logger.info(f"å°†è°ƒç”¨å¤–éƒ¨ä»£ç†æœåŠ¡äº: {PROXY_URL}")
    logger.info("="*60)

    last_activity_time = datetime.now()
    yield
    logger.info("æœåŠ¡å™¨æ­£åœ¨å…³é—­ã€‚")

app = FastAPI(lifespan=lifespan)

# --- CORS ä¸­é—´ä»¶é…ç½® ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- OpenAI æ ¼å¼åŒ–è¾…åŠ©å‡½æ•° (ç”¨äºå³æ—¶è¿”å›) ---
def format_openai_chunk(content: str, model: str, request_id: str) -> str:
    """æ ¼å¼åŒ–ä¸º OpenAI æµå¼å—ã€‚"""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {"content": content}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

def format_openai_finish_chunk(model: str, request_id: str, reason: str = 'stop') -> str:
    """æ ¼å¼åŒ–ä¸º OpenAI ç»“æŸå—ã€‚"""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\ndata: [DONE]\n\n"

def format_openai_non_stream_response(content: str, model: str, request_id: str, reason: str = 'stop') -> dict:
    """æ„å»ºç¬¦åˆ OpenAI è§„èŒƒçš„éæµå¼å“åº”ä½“ã€‚"""
    return {
        "id": request_id,
        "object": "chat.completion",
        "created": int(time.time()),
        "model": model,
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": content},
            "finish_reason": reason,
        }],
        "usage": { "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0 },
    }

# --- API ç«¯ç‚¹ ---
@app.get("/v1/models")
async def get_models():
    """æä¾›ä¸€ä¸ªå›ºå®šçš„æ¨¡å‹ 'leinao_arena'ï¼Œç”¨äºè§¦å‘å¯¹æˆ˜æ¨¡å¼ã€‚"""
    return {
        "object": "list",
        "data": [
            {
                "id": "leinao_arena",
                "object": "model",
                "created": int(time.time()),
                "owned_by": "API_Battle_Server"
            }
        ],
    }

@app.get("/v1/leaderboard")
async def get_leaderboard():
    """æä¾›æ¨¡å‹ ELO æ’è¡Œæ¦œã€‚"""
    leaderboard_data = elo_manager.get_leaderboard()
    return JSONResponse(content=leaderboard_data)

async def stream_proxy_response(response: httpx.Response, display_model_name: str):
    """å°†æ¥è‡ªå¤–éƒ¨ä»£ç†çš„æµå¼å“åº”è½¬å‘ç»™å®¢æˆ·ç«¯ã€‚"""
    request_id = f"chatcmpl-{uuid.uuid4()}"
    try:
        async for chunk in response.aiter_bytes():
            # ç›´æ¥è½¬å‘åŸå§‹æ•°æ®å—
            yield chunk
    except Exception as e:
        logger.error(f"ä»£ç†æµè½¬å‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # å¦‚æœå‡ºé”™ï¼Œå‘é€ä¸€ä¸ªé”™è¯¯å—
        error_content = f"\n\n[Battle Server Error]: ä»£ç†æµåœ¨è½¬å‘æ—¶ä¸­æ–­: {e}"
        yield format_openai_chunk(error_content, display_model_name, request_id).encode('utf-8')
        yield format_openai_finish_chunk(display_model_name, request_id).encode('utf-8')

@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """
    å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚ã€‚æ­¤ç«¯ç‚¹ç°åœ¨ä¸“ç”¨äºå¯¹æˆ˜æ¨¡å¼ã€‚
    å®ƒä¼šè°ƒç”¨å¤–éƒ¨çš„ä»£ç†æœåŠ¡æ¥è·å–æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ã€‚
    """
    global last_activity_time
    last_activity_time = datetime.now()

    # --- API Key éªŒè¯ ---
    api_key = CONFIG.get("api_key")
    if api_key:
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            raise HTTPException(
                status_code=401,
                detail="æœªæä¾› API Keyã€‚è¯·åœ¨ Authorization å¤´éƒ¨ä¸­ä»¥ 'Bearer YOUR_KEY' æ ¼å¼æä¾›ã€‚"
            )
        
        provided_key = auth_header.split(' ')[1]
        if provided_key != api_key:
            raise HTTPException(
                status_code=401,
                detail="æä¾›çš„ API Key ä¸æ­£ç¡®ã€‚"
            )
    
    try:
        openai_req = await request.json()
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ JSON è¯·æ±‚ä½“")

    # æ–°å¢ï¼šæ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦ä¸º "leinao_arena"
    if openai_req.get("model") != "leinao_arena":
        raise HTTPException(status_code=400, detail="æ¨¡å‹åç§°ä¸æ­£ç¡®ï¼Œå¿…é¡»ä¸º 'leinao_arena'ã€‚")

    # å¼ºåˆ¶å¯¹æˆ˜æ¨¡å¼
    if not openai_req.get("extra_body", {}).get("battle_mode_active"):
        raise HTTPException(status_code=400, detail="æ­¤æœåŠ¡å™¨ä»…æ¥å—å¯¹æˆ˜æ¨¡å¼ (battle_mode_active: true) çš„è¯·æ±‚ã€‚")
    
    logger.info("æ£€æµ‹åˆ°å¯¹æˆ˜æ¨¡å¼è¯·æ±‚ï¼Œè¿›å…¥å¤„ç†æµç¨‹...")
    result = battle_mode_handler.handle_battle_mode_request(openai_req)
    result_type, result_data = result

    # --- å¤„ç† WIN æˆ– ERROR æŒ‡ä»¤ ---
    # è¿™ä¸¤ç§æƒ…å†µä¸éœ€è¦è°ƒç”¨å¤–éƒ¨ä»£ç†ï¼Œç›´æ¥è¿”å›ç»“æœ
    if result_type in ['WIN', 'ERROR']:
        is_stream = openai_req.get("stream", True)
        response_id = f"chatcmpl-{uuid.uuid4()}"

        if result_type == 'WIN':
            win_data = result_data
            response_content = (
                f"å¯¹æˆ˜ç»“æœå·²æˆåŠŸè®°å½•ã€‚\nRPID: {win_data['rpid']}\n"
                f"--------------------\n"
                f"A: {win_data['model_a']} vs B: {win_data['model_b']}"
            )
            model_name_for_response = "battle_results"
        else: # ERROR
            response_content = f"[å¯¹æˆ˜æ¨¡å¼é”™è¯¯]: {result_data}"
            model_name_for_response = "battle_error"

        if is_stream:
            async def _instant_stream_response(content, model_name, request_id):
                yield format_openai_chunk(content, model_name, request_id)
                yield format_openai_finish_chunk(model_name, request_id)
            return StreamingResponse(
                _instant_stream_response(response_content, model_name_for_response, response_id),
                media_type="text/event-stream"
            )
        else:
            response_data = format_openai_non_stream_response(
                response_content, model_name_for_response, response_id
            )
            return JSONResponse(content=response_data)

    # --- å¤„ç† GENERATE æŒ‡ä»¤ ---
    # è¿™ç§æƒ…å†µéœ€è¦è°ƒç”¨å¤–éƒ¨ä»£ç†æœåŠ¡
    elif result_type == 'GENERATE':
        processed_req, display_model_name = result_data
        is_stream = processed_req.get("stream", True)
        
        # ç¡®ä¿è¯·æ±‚ä½“ä¸­åŒ…å« model å­—æ®µï¼Œä»£ç†æœåŠ¡éœ€è¦å®ƒ
        if "model" not in processed_req:
             raise HTTPException(status_code=400, detail="[Battle Server Error]: ç”Ÿæˆè¯·æ±‚ä¸­ç¼ºå°‘ 'model' å­—æ®µã€‚")

        logger.info(f"æ­£åœ¨å‘ä»£ç†æœåŠ¡ ({PROXY_URL}) è¯·æ±‚æ¨¡å‹ '{processed_req['model']}' çš„å“åº”...")

        try:
            async with httpx.AsyncClient(timeout=360.0) as client:
                # å‡†å¤‡è¯·æ±‚å¤´ï¼Œå¦‚æœåŸå§‹è¯·æ±‚æœ‰ Authorizationï¼Œå¯ä»¥è€ƒè™‘è½¬å‘
                headers = {"Content-Type": "application/json"}
                
                # å‘èµ·è¯·æ±‚åˆ°ä»£ç†æœåŠ¡
                proxy_response = await client.post(
                    f"{PROXY_URL}/v1/chat/completions",
                    json=processed_req,
                    headers=headers
                )
                proxy_response.raise_for_status()

                if is_stream:
                    # å°†ä»£ç†çš„æµå¼å“åº”ç›´æ¥è½¬å‘ç»™å®¢æˆ·ç«¯
                    return StreamingResponse(
                        stream_proxy_response(proxy_response, display_model_name),
                        media_type="text/event-stream"
                    )
                else:
                    # ç­‰å¾…å¹¶è¿”å›éæµå¼å“åº”
                    response_data = await proxy_response.aread()
                    return Response(content=response_data, media_type="application/json")

        except httpx.ConnectError as e:
            logger.error(f"æ— æ³•è¿æ¥åˆ°ä»£ç†æœåŠ¡: {e}")
            raise HTTPException(status_code=503, detail=f"æ— æ³•è¿æ¥åˆ°å¤–éƒ¨ä»£ç†æœåŠ¡ ({PROXY_URL})ã€‚è¯·ç¡®ä¿ä»£ç†æœåŠ¡æ­£åœ¨è¿è¡Œã€‚")
        except httpx.HTTPStatusError as e:
            # å°è¯•è§£æä»£ç†è¿”å›çš„é”™è¯¯ä¿¡æ¯
            error_detail = e.response.text
            logger.error(f"ä»£ç†æœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ {e.response.status_code}: {error_detail}")
            raise HTTPException(status_code=e.response.status_code, detail=f"ä»£ç†æœåŠ¡å‡ºé”™: {error_detail}")
        except Exception as e:
            logger.error(f"è°ƒç”¨ä»£ç†æœåŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"è°ƒç”¨ä»£ç†æœåŠ¡æ—¶å‘ç”ŸæœªçŸ¥å†…éƒ¨é”™è¯¯: {e}")
    
    else:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥çš„ battle_mode_handler è¿”å›ç±»å‹: {result_type}")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # ä½¿ç”¨ config.jsonc ä¸­çš„ç«¯å£æˆ–é»˜è®¤å€¼
    load_config()
    api_port = CONFIG.get("battle_server_port", 5103) # ä½¿ç”¨æ–°ç«¯å£é¿å…ä¸ä»£ç†å†²çª
    
    logger.info(f"ğŸš€ LMArena å¯¹æˆ˜æœåŠ¡å™¨ v3.0 æ­£åœ¨å¯åŠ¨...")
    logger.info(f"   - ç›‘å¬åœ°å€: http://127.0.0.1:{api_port}")
    
    uvicorn.run(app, host="0.0.0.0", port=api_port)
